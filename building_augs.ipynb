{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "# set gpu device\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "torch.use_deterministic_algorithms(True)\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the batch x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in data ------------------------------------------------------------\n",
    "import My_Anom_extargs as args\n",
    "sys.path.insert(1, '/remote/gpu05/rueschkamp/projects/torch_datasets/')\n",
    "from semi_dataset import SemiV_Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "#starting training loader --------------------------------------\n",
    "\n",
    "\n",
    "training_set = SemiV_Dataset(\n",
    "                                    data_path = args.data_path,\n",
    "                                    signal_origin= \"qcd\",\n",
    "                                    usage= \"training\",\n",
    "                                    number_constit= args.n_constit,\n",
    "                                    number_of_jets= 1e2,\n",
    "                                    ratio=0.2\n",
    "                                    )\n",
    "\n",
    "dl_training = DataLoader(training_set,batch_size=1, shuffle=True)\n",
    "\n",
    "for i,(data,labels) in enumerate(dl_training):\n",
    "\n",
    "    x = data\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randint(0,20,[128, 3, 50])\n",
    "x = torch.ones([128, 3, 50])*20\n",
    "\n",
    "pTs= torch.ones([128, 50])*10\n",
    "etas = torch.ones([128, 50])*100\n",
    "phis = torch.ones([128, 50])*1000\n",
    "x = torch.cat((pTs.unsqueeze(1),etas.unsqueeze(1),phis.unsqueeze(1)),axis = 1)\n",
    "\n",
    "x = x = torch.ones([1, 3, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Augmentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic fkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_pts(batch):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of pT-rescaled jets, each constituent pT is rescaled by 600, same shape as input\n",
    "    '''\n",
    "    batch_rscl = batch.clone()\n",
    "    batch_rscl[:,0,:] = torch.nan_to_num(batch_rscl[:,0,:]/600, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return batch_rscl\n",
    "\n",
    "def recentre_jet(batch):\n",
    "    batchc = batch.clone()\n",
    "    nj = batch.shape[0]\n",
    "    pts = batch[:,0,:]\n",
    "    etas = batch[:,1,:]\n",
    "    phis = batch[:,2,:]\n",
    "    nc = len( pts )\n",
    "    eta_shift = torch.sum(  pts*etas  ) / torch.sum( pts )\n",
    "    phi_shift = torch.sum(  pts*phis ) / torch.sum( pts )\n",
    "    batchc[:,1,:] = batch[:,1,:] - eta_shift\n",
    "    batchc[:,2,:] = batch[:,2,:] - phi_shift\n",
    "    return batchc\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking recentre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "def recentre_jet_np(batch):\n",
    "    batchc = batch.copy()\n",
    "    nj = batch.shape[0]\n",
    "    for i in range( nj ):\n",
    "        pts = batch[i,0,:]\n",
    "        etas = batch[i,1,:]\n",
    "        phis = batch[i,2,:]\n",
    "        nc = len( pts )\n",
    "        eta_shift = np.sum( [ pts[j]*etas[j] for j in range( nc ) ] ) / np.sum( pts )\n",
    "        phi_shift = np.sum( [ pts[j]*phis[j] for j in range( nc ) ] ) / np.sum( pts )\n",
    "        batchc[i,1,:] = batch[i,1,:] - eta_shift\n",
    "        batchc[i,2,:] = batch[i,2,:] - phi_shift\n",
    "    return batchc\n",
    "\n",
    "t = recentre_jet(x)\n",
    "n = recentre_jet_np(x.cpu().numpy())\n",
    "\n",
    "print(t.cpu().numpy() - n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def rescale_pt_np(dataset):\n",
    "    for i in range(0, dataset.shape[0]):\n",
    "        dataset[i,0,:] = dataset[i,0,:]/600\n",
    "    return dataset\n",
    "\n",
    "t = rescale_pts(x).cpu()\n",
    "n = rescale_pt_np(x.cpu().numpy())\n",
    "\n",
    "print(t.numpy() - n)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f079004feb0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_constits_jet( batch, prob=0.5 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    Dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets where each jet has some fraction of missing constituents\n",
    "    Note: rescale pts so that the augmented jet pt matches the original\n",
    "    '''\n",
    "    batch_dropped = batch.clone()\n",
    "    #n_nonzero = torch.sum(batch_dropped[:,0,:]>0, dim=1)\n",
    "    nj = batch_dropped.shape[0]\n",
    "    nc = batch_dropped.shape[2]\n",
    "    torch.manual_seed(42)\n",
    "    mask = torch.rand((nj, nc)) > prob\n",
    "    print(\"first mask:\",mask)\n",
    "    mask = mask.int().to(device)\n",
    "    print(mask)\n",
    "    num_zeros_tensor = (mask == 0).sum().item()\n",
    "    #print(num_zeros_tensor)\n",
    "    batch_dropped = batch_dropped * mask.unsqueeze(1)\n",
    "\n",
    "    #print(batch_dropped)\n",
    "    pts = torch.sum( batch[:,0,:], axis=1 )\n",
    "    pts_aug = torch.sum( batch_dropped[:,0,:], axis=1 )\n",
    "\n",
    "    pts_aug[pts_aug == 0] = 1\n",
    "    pt_rescale = pts/pts_aug\n",
    "\n",
    "    pTs= batch_dropped[:,0,:]\n",
    "    etas = batch_dropped[:,1,:]\n",
    "    phis = batch_dropped[:,2,:]\n",
    "    pTs *= pt_rescale.unsqueeze(1)\n",
    "    \n",
    "    batch_dropped = torch.cat((pTs.unsqueeze(1),etas.unsqueeze(1),phis.unsqueeze(1)),axis = 1)\n",
    "\n",
    "    #print(batch_dropped.size())\n",
    "    return recentre_jet( batch_dropped )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first mask: tensor([[False,  True, False,  True, False, False, False, False,  True, False,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True, False, False, False, False, False, False,  True, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]])\n",
      "tensor([[0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "         0, 0]], device='cuda:0', dtype=torch.int32)\n",
      "first mask: tensor([[False,  True, False,  True, False, False, False, False,  True, False,\n",
      "          True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True, False, False, False, False, False, False,  True, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]])\n",
      "[[0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 1 0 0 0 0 0 0]]\n",
      "torch.Size([1, 3, 50])\n",
      "tensor([[[ 0.0000e+00,  1.4279e+02,  0.0000e+00,  3.6565e+01,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0555e+01,  0.0000e+00,\n",
      "           9.2504e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [-1.8001e-02, -2.7320e-02, -1.8001e-02, -2.5746e-02, -1.8001e-02,\n",
      "          -1.8001e-02, -1.8001e-02, -1.8001e-02, -5.0226e-02, -1.8001e-02,\n",
      "           6.3508e-01, -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02,\n",
      "          -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02,\n",
      "          -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02,\n",
      "          -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02,\n",
      "          -6.6120e-01, -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02,\n",
      "          -1.8001e-02, -1.8001e-02, -6.6120e-01, -1.8001e-02, -1.8001e-02,\n",
      "          -1.8001e-02, -1.8001e-02, -1.8001e-02, -6.6120e-01, -1.8001e-02,\n",
      "          -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02, -1.8001e-02],\n",
      "         [-4.0330e-03,  6.7794e-03, -4.0330e-03,  2.1966e-02, -4.0330e-03,\n",
      "          -4.0330e-03, -4.0330e-03, -4.0330e-03,  2.3090e-02, -4.0330e-03,\n",
      "          -2.4278e-01, -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03,\n",
      "          -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03,\n",
      "          -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03,\n",
      "          -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03,\n",
      "          -2.6370e+00, -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03,\n",
      "          -4.0330e-03, -4.0330e-03, -2.6370e+00, -4.0330e-03, -4.0330e-03,\n",
      "          -4.0330e-03, -4.0330e-03, -4.0330e-03, -2.6370e+00, -4.0330e-03,\n",
      "          -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03, -4.0330e-03]]],\n",
      "       device='cuda:0')\n",
      "[[[ 0.0000000e+00  1.4278870e+02  0.0000000e+00  3.6565487e+01\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    2.0554512e+01  0.0000000e+00  9.2503700e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00]\n",
      "  [-1.8000942e-02 -2.7319532e-02 -1.8000942e-02 -2.5746088e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -1.8000942e-02\n",
      "   -5.0226133e-02 -1.8000942e-02  6.3507855e-01 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -6.6120362e-01 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -1.8000942e-02\n",
      "   -1.8000942e-02 -6.6120362e-01 -1.8000942e-02 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -6.6120362e-01\n",
      "   -1.8000942e-02 -1.8000942e-02 -1.8000942e-02 -1.8000942e-02\n",
      "   -1.8000942e-02 -1.8000942e-02]\n",
      "  [-4.0330337e-03  6.7794425e-03 -4.0330337e-03  2.1966469e-02\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -4.0330337e-03\n",
      "    2.3090135e-02 -4.0330337e-03 -2.4278472e-01 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03 -2.6369627e+00 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -4.0330337e-03\n",
      "   -4.0330337e-03 -2.6369627e+00 -4.0330337e-03 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -2.6369627e+00\n",
      "   -4.0330337e-03 -4.0330337e-03 -4.0330337e-03 -4.0330337e-03\n",
      "   -4.0330337e-03 -4.0330337e-03]]]\n"
     ]
    }
   ],
   "source": [
    "def drop_constits_jet_np( batch, prob=0.5 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    Dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets where each jet has some fraction of missing constituents\n",
    "    Note: rescale pts so that the augmented jet pt matches the original\n",
    "    '''\n",
    "    batchc = batch.copy()\n",
    "    nj = batchc.shape[0]\n",
    "    nc = batchc.shape[2]\n",
    "    nzs = np.array( [ np.where( batchc[:,0,:]>0.0 )[0].shape[0] for i in range(len(batch)) ] )\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    mask = torch.rand((nj, nc)) > prob\n",
    "    print(\"first mask:\",mask)\n",
    "    mask = mask.int()\n",
    "    mask = mask.numpy()\n",
    "    print(mask)\n",
    "    num_zeros_array = ((np.array(mask)) == 0).sum()\n",
    "    #print(num_zeros_array)\n",
    "\n",
    "    for i in range( nj ):\n",
    "        for j in range( nc ):\n",
    "            if mask[i][j]==0:\n",
    "                batchc[i,:,j] = np.array([0.0,0.0,0.0])\n",
    "    pts = np.sum( batch[:,0,:], axis=1 )\n",
    "    pts_aug = np.sum( batchc[:,0,:], axis=1 )\n",
    "    pt_rescale = [ pts[i]/pts_aug[i] for i in range(nj) ]\n",
    "    for i in range(nj):\n",
    "        batchc[i,0,:] = batchc[i,0,:]*pt_rescale[i]\n",
    "    return recentre_jet_np( batchc )\n",
    "\n",
    "x=x.to(device)\n",
    "t = drop_constits_jet(x,0.9)\n",
    "n = drop_constits_jet_np(x.cpu().numpy(),0.9)\n",
    "\n",
    "\n",
    "print(x.size())\n",
    "print(t)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_constits_jet_ordered( batch, prob=0.5 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    Dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets where each jet has some fraction of missing constituents\n",
    "    Note: rescale pts so that the augmented jet pt matches the original\n",
    "    '''\n",
    "    batch_dropped = batch.clone()\n",
    "    #n_nonzero = torch.sum(batch_dropped[:,0,:]>0, dim=1)\n",
    "    nj = batch_dropped.shape[0]\n",
    "    nc = batch_dropped.shape[2]\n",
    "    torch.manual_seed(42)\n",
    "    mask = torch.rand((nj, nc)) > prob\n",
    "    mask = mask.int().to(device)\n",
    "    num_zeros_tensor = (mask == 0).sum().item()\n",
    "    #print(num_zeros_tensor)\n",
    "    batch_dropped = batch_dropped * mask.unsqueeze(1)\n",
    "\n",
    "    #print(batch_dropped)\n",
    "    pts = torch.sum( batch[:,0,:], axis=1 )\n",
    "    pts_aug = torch.sum( batch_dropped[:,0,:], axis=1 )\n",
    "\n",
    "    pts_aug[pts_aug == 0] = 1\n",
    "    pt_rescale = pts/pts_aug\n",
    "\n",
    "    pTs= batch_dropped[:,0,:]\n",
    "    pTs *= pt_rescale.unsqueeze(1)\n",
    "    pTs, indices = torch.sort(pTs, dim=1, descending=True) # Ordering pTs\n",
    "    etas = batch_dropped[:,1,:]\n",
    "    etas = etas.gather(dim=1,index=indices)\n",
    "    phis = batch_dropped[:,2,:]\n",
    "    phis = phis.gather(dim=1,index=indices)\n",
    "\n",
    "    \n",
    "    batch_dropped = torch.cat((pTs.unsqueeze(1),etas.unsqueeze(1),phis.unsqueeze(1)),axis = 1)\n",
    "\n",
    "    #print(batch_dropped.size())\n",
    "    return recentre_jet( batch_dropped )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first mask: tensor([[ True,  True, False,  True, False,  True, False,  True,  True, False,\n",
      "          True,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
      "         False, False, False,  True, False, False, False, False,  True, False,\n",
      "          True, False,  True,  True, False,  True,  True,  True,  True, False,\n",
      "          True, False,  True,  True,  True, False,  True,  True,  True, False]])\n",
      "tensor([[1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "         0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "         1, 0]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[ 1.1189e+02,  3.7674e+01,  1.5382e+01,  3.1732e+00,  2.1747e+00,\n",
      "           1.9729e+00,  1.6918e+00,  1.6153e+00,  1.3249e+00,  8.8348e-01,\n",
      "           4.9134e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 5.5647e-03, -4.8385e-03, -6.5957e-03, -4.3724e-02, -9.6410e-02,\n",
      "           2.1968e-01, -4.6720e-01,  3.8419e-01,  1.1392e-01, -5.6998e-01,\n",
      "           2.0050e-01,  9.4653e-01, -3.4507e-03,  9.4653e-01,  9.4653e-01,\n",
      "          -3.4507e-03, -3.4507e-03, -3.4507e-03, -3.4507e-03, -3.4507e-03,\n",
      "          -3.4507e-03,  9.4653e-01,  9.4653e-01,  9.4653e-01,  9.4653e-01,\n",
      "          -3.4507e-03,  9.4653e-01, -3.4507e-03, -3.4507e-03,  9.4653e-01,\n",
      "           9.4653e-01, -3.4507e-03,  9.4653e-01,  9.4653e-01, -3.4507e-03,\n",
      "           9.4653e-01,  9.4653e-01, -3.4507e-03, -3.4507e-03, -3.4507e-03,\n",
      "           9.4653e-01, -3.4507e-03,  9.4653e-01,  9.4653e-01, -3.4507e-03,\n",
      "          -3.4507e-03,  9.4653e-01, -3.4507e-03, -3.4507e-03,  9.4653e-01],\n",
      "         [-2.4420e-01, -2.0445e-01, -2.3286e-01, -2.4745e-01, -2.1440e-01,\n",
      "           5.4681e+00,  5.8194e+00,  5.6527e+00,  5.6765e+00, -1.2557e-01,\n",
      "           5.4683e+00, -3.1771e-01,  6.6227e-02, -3.1771e-01, -3.1771e-01,\n",
      "           6.6227e-02,  6.6227e-02,  6.6227e-02,  6.6227e-02,  6.6227e-02,\n",
      "           6.6227e-02, -3.1771e-01, -3.1771e-01, -3.1771e-01, -3.1771e-01,\n",
      "           6.6227e-02, -3.1771e-01,  6.6227e-02,  6.6227e-02, -3.1771e-01,\n",
      "          -3.1771e-01,  6.6227e-02, -3.1771e-01, -3.1771e-01,  6.6227e-02,\n",
      "          -3.1771e-01, -3.1771e-01,  6.6227e-02,  6.6227e-02,  6.6227e-02,\n",
      "          -3.1771e-01,  6.6227e-02, -3.1771e-01, -3.1771e-01,  6.6227e-02,\n",
      "           6.6227e-02, -3.1771e-01,  6.6227e-02,  6.6227e-02, -3.1771e-01]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[ 1.1189e+02,  3.7674e+01,  0.0000e+00,  1.5382e+01,  0.0000e+00,\n",
      "           3.1732e+00,  0.0000e+00,  2.1747e+00,  1.9729e+00,  0.0000e+00,\n",
      "           1.6918e+00,  1.6153e+00,  1.3249e+00,  8.8348e-01,  4.9134e-01,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 5.5647e-03, -4.8385e-03, -3.4507e-03, -6.5957e-03, -3.4507e-03,\n",
      "          -4.3724e-02, -3.4507e-03, -9.6410e-02,  2.1968e-01, -3.4507e-03,\n",
      "          -4.6720e-01,  3.8419e-01,  1.1392e-01, -5.6998e-01,  2.0050e-01,\n",
      "          -3.4507e-03,  9.4653e-01,  9.4653e-01, -3.4507e-03,  9.4653e-01,\n",
      "          -3.4507e-03, -3.4507e-03, -3.4507e-03,  9.4653e-01, -3.4507e-03,\n",
      "          -3.4507e-03, -3.4507e-03, -3.4507e-03,  9.4653e-01, -3.4507e-03,\n",
      "           9.4653e-01, -3.4507e-03,  9.4653e-01,  9.4653e-01, -3.4507e-03,\n",
      "           9.4653e-01,  9.4653e-01,  9.4653e-01,  9.4653e-01, -3.4507e-03,\n",
      "           9.4653e-01, -3.4507e-03,  9.4653e-01,  9.4653e-01,  9.4653e-01,\n",
      "          -3.4507e-03,  9.4653e-01,  9.4653e-01,  9.4653e-01, -3.4507e-03],\n",
      "         [-2.4420e-01, -2.0445e-01,  6.6227e-02, -2.3286e-01,  6.6227e-02,\n",
      "          -2.4745e-01,  6.6227e-02, -2.1440e-01,  5.4681e+00,  6.6227e-02,\n",
      "           5.8194e+00,  5.6527e+00,  5.6765e+00, -1.2557e-01,  5.4683e+00,\n",
      "           6.6227e-02, -3.1771e-01, -3.1771e-01,  6.6227e-02, -3.1771e-01,\n",
      "           6.6227e-02,  6.6227e-02,  6.6227e-02, -3.1771e-01,  6.6227e-02,\n",
      "           6.6227e-02,  6.6227e-02,  6.6227e-02, -3.1771e-01,  6.6227e-02,\n",
      "          -3.1771e-01,  6.6227e-02, -3.1771e-01, -3.1771e-01,  6.6227e-02,\n",
      "          -3.1771e-01, -3.1771e-01, -3.1771e-01, -3.1771e-01,  6.6227e-02,\n",
      "          -3.1771e-01,  6.6227e-02, -3.1771e-01, -3.1771e-01, -3.1771e-01,\n",
      "           6.6227e-02, -3.1771e-01, -3.1771e-01, -3.1771e-01,  6.6227e-02]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y = drop_constits_jet_ordered(x)\n",
    "z= drop_constits_jet(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pT reweight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_reweight_jet( batch, beta=1.5 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    Dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets where the pt of the constituents in each jet has has been re-weighted by some power\n",
    "    Note: rescale pts so that the augmented jet pt matches the original\n",
    "    '''\n",
    "    batchc = batch.clone()\n",
    "\n",
    "    etas = batchc[:,1,:]\n",
    "    phis = batchc[:,2,:]\n",
    "    batchc = batchc[:,0,:]**beta\n",
    "    pts = torch.sum( batch[:,0,:], axis=1 )\n",
    "    pts_aug = torch.sum( batchc, axis=1 )\n",
    "\n",
    "    pts_aug[pts_aug == 0] = 1\n",
    "    pt_rescale =  pts/pts_aug\n",
    "    pTs = pt_rescale.unsqueeze(-1)* batchc\n",
    "    #print(pTs)\n",
    "\n",
    "    jet = torch.cat((pTs.unsqueeze(1),etas.unsqueeze(1),phis.unsqueeze(1)),axis = 1)\n",
    "    return recentre_jet( jet.float() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def pt_reweight_jet_np( batch, beta=1.5 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    Dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets where the pt of the constituents in each jet has has been re-weighted by some power\n",
    "    Note: rescale pts so that the augmented jet pt matches the original\n",
    "    '''\n",
    "    batchc = batch.copy()\n",
    "    nj = batchc.shape[0]\n",
    "    nc = batchc.shape[2]\n",
    "    for i in range( nj ):\n",
    "        for j in range( nc ):\n",
    "            batchc[i,0,j] = batch[i,0,j]**beta\n",
    "    pts = np.sum( batch[:,0,:], axis=1 )\n",
    "    pts_aug = np.sum( batchc[:,0,:], axis=1 )\n",
    "    pt_rescale = [ pts[i]/pts_aug[i] for i in range(nj) ]\n",
    "    for i in range(nj):\n",
    "        batchc[i,0,:] = batchc[i,0,:]*pt_rescale[i]\n",
    "    #print(batchc[:,0,:])\n",
    "    return recentre_jet_np( batchc )\n",
    "\n",
    "t = pt_reweight_jet(x)\n",
    "n = pt_reweight_jet_np(x.cpu().numpy())\n",
    "\n",
    "print(t.cpu().numpy() - n)\n",
    "print(t - torch.Tensor(n).to(device))\n",
    "#print(t - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_reweight_jet_ordered( batch, beta=1.5 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    Dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets where the pt of the constituents in each jet has has been re-weighted by some power\n",
    "    Note: rescale pts so that the augmented jet pt matches the original\n",
    "    '''\n",
    "    batchc = batch.clone()\n",
    "\n",
    "    etas = batchc[:,1,:]\n",
    "    phis = batchc[:,2,:]\n",
    "    batchc = batchc[:,0,:]**beta\n",
    "    pts = torch.sum( batch[:,0,:], axis=1 )\n",
    "    pts_aug = torch.sum( batchc, axis=1 )\n",
    "\n",
    "    pts_aug[pts_aug == 0] = 1\n",
    "    pt_rescale =  pts/pts_aug\n",
    "    pTs = pt_rescale.unsqueeze(-1)* batchc\n",
    "    #print(pTs)\n",
    "    pTs, indices = torch.sort(pTs, dim=1, descending=True) # Ordering pTs\n",
    "    etas = batch_dropped[:,1,:]\n",
    "    etas = etas.gather(dim=1,index=indices)\n",
    "    phis = batch_dropped[:,2,:]\n",
    "    phis = phis.gather(dim=1,index=indices)\n",
    "\n",
    "    jet = torch.cat((pTs.unsqueeze(1),etas.unsqueeze(1),phis.unsqueeze(1)),axis = 1)\n",
    "    return recentre_jet( jet.float() )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jets(batch):\n",
    "    batch_filled = batch.clone()\n",
    "    n_constit = batch_filled.shape[2]\n",
    "    n_nonzero = torch.sum(batch_filled[:,0,:]>0, dim=1) #number of zero constituents\n",
    "    print(n_nonzero)\n",
    "    n_split = torch.min(torch.stack([n_nonzero, n_constit-n_nonzero], dim=1), dim=1).values\n",
    "    print(n_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33, 26, 21, 25, 22, 29, 23, 24, 27, 27, 27, 21, 24, 22, 22, 28, 24, 29,\n",
      "        26, 31, 26, 27, 27, 25, 23, 26, 27, 23, 26, 23, 27, 25, 29, 25, 27, 20,\n",
      "        22, 26, 33, 20, 28, 27, 25, 26, 16, 22, 23, 26, 30, 27, 28, 21, 27, 25,\n",
      "        23, 26, 22, 24, 26, 25, 24, 23, 29, 21, 29, 25, 23, 20, 26, 20, 30, 21,\n",
      "        28, 25, 27, 17, 26, 22, 19, 25, 18, 24, 26, 29, 25, 28, 21, 26, 17, 26,\n",
      "        25, 26, 23, 20, 23, 27, 28, 21, 24, 22, 27, 24, 12, 27, 25, 24, 24, 28,\n",
      "        28, 23, 26, 25, 26, 23, 32, 32, 28, 24, 29, 28, 29, 23, 24, 22, 26, 26,\n",
      "        28, 24])\n",
      "tensor([17, 24, 21, 25, 22, 21, 23, 24, 23, 23, 23, 21, 24, 22, 22, 22, 24, 21,\n",
      "        24, 19, 24, 23, 23, 25, 23, 24, 23, 23, 24, 23, 23, 25, 21, 25, 23, 20,\n",
      "        22, 24, 17, 20, 22, 23, 25, 24, 16, 22, 23, 24, 20, 23, 22, 21, 23, 25,\n",
      "        23, 24, 22, 24, 24, 25, 24, 23, 21, 21, 21, 25, 23, 20, 24, 20, 20, 21,\n",
      "        22, 25, 23, 17, 24, 22, 19, 25, 18, 24, 24, 21, 25, 22, 21, 24, 17, 24,\n",
      "        25, 24, 23, 20, 23, 23, 22, 21, 24, 22, 23, 24, 12, 23, 25, 24, 24, 22,\n",
      "        22, 23, 24, 25, 24, 23, 18, 18, 22, 24, 21, 22, 21, 23, 24, 22, 24, 24,\n",
      "        22, 24])\n"
     ]
    }
   ],
   "source": [
    "y = add_jets(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical Augmentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collinear fill jets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collinear_fill_jets_fast(batch):\n",
    "    '''\n",
    "    Fill as many of the zero-padded entries with collinear splittings\n",
    "    of the constituents by splitting each constituent at most once.\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch : torch.Tensor\n",
    "        batch of jets with zero-padding\n",
    "    Returns\n",
    "    -------\n",
    "    batch_filled : torch.Tensor\n",
    "        batch of jets with collinear splittings\n",
    "    '''\n",
    "    batch_filled = batch.clone()\n",
    "    n_constit = batch_filled.shape[2]\n",
    "    n_nonzero = torch.sum(batch_filled[:,0,:]>0, dim=1)\n",
    "    \n",
    "    n_split = torch.min(torch.stack([n_nonzero, n_constit-n_nonzero], dim=1), dim=1).values\n",
    "    idx_flip = torch.where(n_nonzero != n_split)[0]\n",
    "    mask_split = (batch_filled[:,0,:] != 0)\n",
    "    \n",
    "    mask_split[idx_flip] = torch.flip(mask_split[idx_flip].float(), dims=[1]).bool()\n",
    "\n",
    "    #print(mask_split)\n",
    "    mask_split[idx_flip] = ~mask_split[idx_flip]\n",
    "    r_split = torch.rand(size=mask_split.shape, device=batch.device)\n",
    "    \n",
    "    a = r_split*mask_split*batch_filled[:,0,:]\n",
    "    b = (1-r_split)*mask_split*batch_filled[:,0,:]\n",
    "    c = ~mask_split*batch_filled[:,0,:]\n",
    "    batch_filled[:,0,:] = a+c+torch.flip(b, dims=[1])\n",
    "    batch_filled[:,1,:] += torch.flip(mask_split*batch_filled[:,1,:], dims=[1])\n",
    "    batch_filled[:,2,:] += torch.flip(mask_split*batch_filled[:,2,:], dims=[1])\n",
    "    return batch_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collinear_fill_jets_np( batch ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets with collinear splittings, the function attempts to fill as many of the zero-padded args.nconstit\n",
    "    entries with collinear splittings of the constituents by splitting each constituent at most once, same shape as input\n",
    "    '''\n",
    "    batchb = batch.copy()\n",
    "    nc = batch.shape[2]\n",
    "    nzs = np.array( [ np.where( batch[:,0,:][i]>0.0)[0].shape[0] for i in range(len(batch)) ] )\n",
    "    for k in range(len(batch)):\n",
    "        nzs1 = np.max( [ nzs[k], int(nc/2) ] )\n",
    "        zs1 = int(nc-nzs1)\n",
    "        els = np.random.choice( np.linspace(0,nzs1-1,nzs1), size=zs1, replace=False )\n",
    "        rs = np.random.uniform( size=zs1 )\n",
    "        for j in range(zs1):\n",
    "            batchb[k,0,int(els[j])] = rs[j]*batch[k,0,int(els[j])]\n",
    "            batchb[k,0,int(nzs[k]+j)] = (1-rs[j])*batch[k,0,int(els[j])]\n",
    "            batchb[k,1,int(nzs[k]+j)] = batch[k,1,int(els[j])]\n",
    "            batchb[k,2,int(nzs[k]+j)] = batch[k,2,int(els[j])]\n",
    "    return batchb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "t = collinear_fill_jets_fast(x)\n",
    "n = collinear_fill_jets_np(x.cpu().numpy())\n",
    "\n",
    "print(t.cpu().numpy() - n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_jets(batch):\n",
    "\n",
    "    rot_batch = batch # is this right when it should stay on gpu?\n",
    "    batch_size = batch.size(0)\n",
    "    constit = batch.size(2)\n",
    "\n",
    "    rotate_tensor = torch.rand([batch_size,constit]) * 2 * np.pi #creating the array of random rotations\n",
    "\n",
    "    rot_batch[:,2,:] =+ np.pi # shifting the phi tensor to make use of the % function\n",
    "    rot_batch[:,2,:] += rotate_tensor\n",
    "    rot_batch[:,2,:] %= 2 * np.pi # getting it in the same output range\n",
    "    rot_batch[:,2,:] =- np.pi # shifting back\n",
    "\n",
    "    return rot_batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bary does it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def rotate_jets(batch, ra ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets rotated independently in eta-phi, same shape as input\n",
    "    '''\n",
    "    device = batch.device\n",
    "    batch_size = batch.size(0)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    rot_angle = ra\n",
    "    #rot_angle = torch.rand(batch_size, device=\"cpu\") * 2 * np.pi\n",
    "    c = torch.cos(rot_angle)\n",
    "    s = torch.sin(rot_angle)\n",
    "    o = torch.ones_like(rot_angle)\n",
    "    z = torch.zeros_like(rot_angle)\n",
    "\n",
    "    #print(o.shape)\n",
    "\n",
    "    rot_matrix = torch.stack([\n",
    "    torch.stack([o, z, z], dim=0),\n",
    "    torch.stack([z, c, s], dim=0),\n",
    "    torch.stack([z, -s, c], dim=0)], dim=1) # (3, 3, batch_size]\n",
    "\n",
    "    #print(rot_matrix[:,:,0])\n",
    "\n",
    "    return torch.einsum('ijk,lji->ilk', batch, rot_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_jets_np( batch , ra ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets rotated independently in eta-phi, same shape as input\n",
    "    '''\n",
    "\n",
    "    rot_angle = ra\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    #rot_angle = (torch.rand(128, device=\"cpu\") * 2 * np.pi).cpu().numpy()\n",
    "    c = np.cos(rot_angle)\n",
    "    s = np.sin(rot_angle)\n",
    "    o = np.ones_like(rot_angle)\n",
    "    z = np.zeros_like(rot_angle)\n",
    "    rot_matrix = np.array([[o, z, z], [z, c, -s], [z, s, c]]) # (3, 3, batchsize)\n",
    "    return np.einsum('ijk,lji->ilk', batch, rot_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "rot_angle = torch.rand(batch_size, device=\"cpu\") * 2 * np.pi\n",
    "\n",
    "t = rotate_jets(x.cpu(),rot_angle).cpu().numpy()\n",
    "n = rotate_jets_np(x.cpu().numpy(),rot_angle.numpy())\n",
    "\n",
    "print((t- n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "rot_angle = torch.ones(batch_size, device=\"cpu\")\n",
    "\n",
    "c = torch.Tensor([1])#torch.cos(rot_angle)\n",
    "s = torch.Tensor([2])#torch.sin(rot_angle)\n",
    "o = torch.Tensor([3])#torch.ones_like(rot_angle)\n",
    "z = torch.Tensor([4])#torch.zeros_like(rot_angle)\n",
    "\n",
    "rot_matrix = torch.stack([\n",
    "torch.stack([o, z, z], dim=0),\n",
    "torch.stack([z, c, s], dim=0),\n",
    "torch.stack([z, -s, c], dim=0)], dim=1) # (3, 3, batch_size]\n",
    "\n",
    "rot_matrix_np = np.array([[o.numpy(), z.numpy(), z.numpy()], [z.numpy(), c.numpy(), -s.numpy()], [z.numpy(), s.numpy(), c.numpy()]]) # (3, 3, batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3.]\n",
      "  [ 4.]\n",
      "  [ 4.]]\n",
      "\n",
      " [[ 4.]\n",
      "  [ 1.]\n",
      "  [-2.]]\n",
      "\n",
      " [[ 4.]\n",
      "  [ 2.]\n",
      "  [ 1.]]]\n",
      "[[[ 3.]\n",
      "  [ 4.]\n",
      "  [ 4.]]\n",
      "\n",
      " [[ 4.]\n",
      "  [ 1.]\n",
      "  [-2.]]\n",
      "\n",
      " [[ 4.]\n",
      "  [ 2.]\n",
      "  [ 1.]]]\n"
     ]
    }
   ],
   "source": [
    "print(rot_matrix.numpy())\n",
    "print(rot_matrix_np)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distort Jets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def distort_jets(batch, strength=0.1, pT_clip_min=0.1):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets with each constituents position shifted independently, shifts drawn from normal with mean 0, std strength/pT, same shape as input\n",
    "    '''\n",
    "    #strength = torch.Tensor(strength).to(device)\n",
    "    pT = batch[:, 0]  # (batchsize, n_constit)\n",
    "    shift_eta = torch.nan_to_num(\n",
    "        #strength * torch.randn(batch.shape[0], batch.shape[2]).to(device) / pT.clip(min=pT_clip_min).to(device),\n",
    "        strength * torch.ones(batch.shape[0], batch.shape[2]).to(device) / pT.clip(min=pT_clip_min).to(device),\n",
    "        posinf=0.0,\n",
    "        neginf=0.0,\n",
    "    ).to(device)  # * mask\n",
    "    shift_phi = torch.nan_to_num(\n",
    "        #strength * torch.randn(batch.shape[0], batch.shape[2]).to(device) / pT.clip(min=pT_clip_min).to(device),\n",
    "        strength * torch.ones(batch.shape[0], batch.shape[2]).to(device) / pT.clip(min=pT_clip_min).to(device),\n",
    "        posinf=0.0,\n",
    "        neginf=0.0,\n",
    "    ).to(device)  # * mask\n",
    "    shift = torch.stack([torch.zeros((batch.shape[0], batch.shape[2])).to(device), shift_eta, shift_phi], 1)\n",
    "    return batch + shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort_jets_np( batch, strength=0.1, pT_clip_min=0.1 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of jets with each constituents position shifted independently, shifts drawn from normal with mean 0, std strength/pT, same shape as input\n",
    "    '''\n",
    "    pT = batch[:,0]   # (batchsize, n_constit)\n",
    "    #shift_eta = np.nan_to_num( strength * np.random.randn(batch.shape[0], batch.shape[2]) / pT.clip(min=pT_clip_min), posinf = 0.0, neginf = 0.0 )# * mask\n",
    "    #shift_phi = np.nan_to_num( strength * np.random.randn(batch.shape[0], batch.shape[2]) / pT.clip(min=pT_clip_min), posinf = 0.0, neginf = 0.0 )# * mask\n",
    "\n",
    "    shift_eta = np.nan_to_num(strength * np.ones((batch.shape[0], batch.shape[2]), dtype=np.float64) / pT.clip(min=pT_clip_min), posinf=0.0, neginf=0.0)\n",
    "    shift_phi = np.nan_to_num(strength * np.ones((batch.shape[0], batch.shape[2]), dtype=np.float64) / pT.clip(min=pT_clip_min), posinf=0.0, neginf=0.0)\n",
    "\n",
    "    shift = np.stack( [ np.zeros( (batch.shape[0], batch.shape[2]) ), shift_eta, shift_phi ], 1)\n",
    "    return batch + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "   0.00000000e+00 0.00000000e+00]\n",
      "  [2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08]\n",
      "  [2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08 2.38418578e-08 2.38418578e-08\n",
      "   2.38418578e-08 2.38418578e-08]]]\n"
     ]
    }
   ],
   "source": [
    "t = distort_jets(x).cpu()\n",
    "n = distort_jets_np(x.cpu().numpy())\n",
    "\n",
    "print(t.numpy() - n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Jets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def ptp(input, dim=None, keepdim=False):\n",
    "    if dim is None:\n",
    "        return input.max() - input.min()\n",
    "    return input.max(dim, keepdim).values - input.min(dim, keepdim).values\n",
    "\n",
    "\n",
    "def translate_jets(batch, width=1.0):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of eta-phi translated jets, same shape as input\n",
    "    '''\n",
    "\n",
    "    device = batch.device\n",
    "    mask = (batch[:, 0] > 0)  # 1 for constituents with non-zero pT, 0 otherwise\n",
    "    ptp_eta = ptp(batch[:, 1, :], dim=-1, keepdim=True)  # ptp = 'peak to peak' = max - min DOUBLE CHECKED\n",
    "    ptp_phi = ptp(batch[:, 2, :], dim=-1, keepdim=True)  # ptp = 'peak to peak' = max - min\n",
    "    low_eta = -width * ptp_eta\n",
    "    high_eta = +width * ptp_eta\n",
    "    low_phi = torch.max(-width * ptp_phi, -torch.tensor(np.pi, device=device) - torch.amin(batch[:, 2, :], dim=-1, keepdim=True))\n",
    "    high_phi = torch.min(+width * ptp_phi, +torch.tensor(np.pi, device=device) - torch.amax(batch[:, 2, :], dim=-1, keepdim=True)) #DOUBLE CHECKED\n",
    "    shift_eta = mask * torch.rand((batch.shape[0], 1), device=device) * (high_eta - low_eta) + low_eta\n",
    "    shift_phi = mask * torch.rand((batch.shape[0], 1), device=device) * (high_phi - low_phi) + low_phi\n",
    "    shift = torch.stack([torch.zeros((batch.shape[0], batch.shape[2]), device=device), shift_eta, shift_phi], dim=1)\n",
    "    print(shift)\n",
    "    shifted_batch = batch + shift\n",
    "    return shifted_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_jets_np( batch, width=1.0 ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of eta-phi translated jets, same shape as input\n",
    "    '''\n",
    "    \n",
    "    mask = (batch[:,0] > 0) # 1 for constituents with non-zero pT, 0 otherwise\n",
    "    ptp_eta  = np.ptp(batch[:,1,:], axis=-1, keepdims=True) # ptp = 'peak to peak' = max - min\n",
    "    ptp_phi  = np.ptp(batch[:,2,:], axis=-1, keepdims=True) # ptp = 'peak to peak' = max - min\n",
    "    low_eta  = -width*ptp_eta\n",
    "    high_eta = +width*ptp_eta\n",
    "    low_phi  = np.maximum(-width*ptp_phi, -np.pi-np.amin(batch[:,2,:], axis=1).reshape(ptp_phi.shape))\n",
    "    high_phi = np.minimum(+width*ptp_phi, +np.pi-np.amax(batch[:,2,:], axis=1).reshape(ptp_phi.shape))\n",
    "    print(high_phi)\n",
    "    #shift_eta = (mask * torch.rand((batch.shape[0], 1), device=device) * (high_eta - low_eta)).cpu().numpy()\n",
    "    #shift_phi = (mask * torch.rand((batch.shape[0], 1), device=device) * (high_phi - low_phi)).cpu().numpy()\n",
    "\n",
    "    shift_eta = mask*np.random.uniform(low=low_eta, high=high_eta, size=(batch.shape[0], 1))\n",
    "    shift_phi = mask*np.random.uniform(low=low_phi, high=high_phi, size=(batch.shape[0], 1))\n",
    "    shift = np.stack([np.zeros((batch.shape[0], batch.shape[2])), shift_eta, shift_phi], 1)\n",
    "    print(shift)\n",
    "    shifted_batch = batch+shift\n",
    "    return shifted_batch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the random function can not be compared i show here that they are doing the same using the mean and the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1898]], device='cuda:0')\n",
      "tensor([[1.1898]])\n",
      "NumPy random numbers:\n",
      " [[0.5488135  0.71518937 0.60276338 ... 0.32361371 0.81354502 0.69740038]\n",
      " [0.4139625  0.6296183  0.77858426 ... 0.69652287 0.48369661 0.33955073]\n",
      " [0.37479353 0.42868598 0.68305662 ... 0.06915139 0.75806398 0.932006  ]\n",
      " ...\n",
      " [0.50755403 0.45498658 0.00269646 ... 0.30199667 0.45259287 0.35421085]\n",
      " [0.30057139 0.19176931 0.2468228  ... 0.45199921 0.74777253 0.16047437]\n",
      " [0.86403991 0.54683827 0.34085736 ... 0.75526211 0.21382493 0.72614352]]\n",
      "0.4999276664433702 0.08339419508947447\n",
      "PyTorch random numbers:\n",
      " tensor([[0.4963, 0.7682, 0.0885,  ..., 0.2716, 0.3017, 0.0812],\n",
      "        [0.3791, 0.4516, 0.2695,  ..., 0.0580, 0.5345, 0.3919],\n",
      "        [0.9744, 0.2747, 0.1823,  ..., 0.0410, 0.7614, 0.3119],\n",
      "        ...,\n",
      "        [0.1531, 0.0114, 0.2678,  ..., 0.0205, 0.8479, 0.0535],\n",
      "        [0.5164, 0.8979, 0.1201,  ..., 0.9679, 0.2169, 0.3057],\n",
      "        [0.9008, 0.1807, 0.2671,  ..., 0.9723, 0.3218, 0.6172]])\n",
      "tensor(0.5004) tensor(0.0833)\n"
     ]
    }
   ],
   "source": [
    "batch = x\n",
    "ptp_eta = ptp(batch[:, 1, :], dim=-1, keepdim=True) \n",
    "batch = batch.cpu()\n",
    "ptp_eta_np  = np.ptp(batch[:,1,:], axis=-1, keepdims=True) # ptp = 'peak to peak' = max - min\n",
    "\n",
    "print(ptp_eta)\n",
    "print(ptp_eta_np)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Parameters for uniform distribution\n",
    "low = 0.0\n",
    "high = 1.0\n",
    "size = (200, 3000)  # Shape of the output array\n",
    "\n",
    "# Generate random numbers using np.random.uniform()\n",
    "np_uniform = np.random.uniform(low=low, high=high, size=size)\n",
    "print(\"NumPy random numbers:\\n\", np_uniform)\n",
    "print(np.mean(np_uniform),np.var(np_uniform))\n",
    "# Generate random numbers using torch.rand()\n",
    "torch_uniform = low + (high - low) * torch.rand(size)\n",
    "print(\"PyTorch random numbers:\\n\", torch_uniform)\n",
    "print(torch.mean(torch_uniform),torch.var(torch_uniform))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_pts(batch):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of pT-normalised jets, pT in each jet sums to 1, same shape as input\n",
    "    '''\n",
    "    batch_norm = batch.clone()\n",
    "    batch_norm[:, 0, :] = torch.nan_to_num(batch_norm[:, 0, :] / torch.sum(batch_norm[:, 0, :], dim=1)[:, None], posinf=0.0, neginf=0.0)\n",
    "    return batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_pts_np( batch ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of pT-normalised jets, pT in each jet sums to 1, same shape as input\n",
    "    '''\n",
    "    batch_norm = batch.copy()\n",
    "    batch_norm[:,0,:] = np.nan_to_num(batch_norm[:,0,:]/np.sum(batch_norm[:,0,:], axis=1)[:, np.newaxis], posinf = 0.0, neginf = 0.0 )\n",
    "    return batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.4901161e-08 -1.4901161e-08 -1.4901161e-08 -7.4505806e-09\n",
      "   -7.4505806e-09 -7.4505806e-09 -3.7252903e-09  0.0000000e+00\n",
      "   -1.8626451e-09 -3.7252903e-09 -1.8626451e-09 -1.8626451e-09\n",
      "   -1.8626451e-09 -1.8626451e-09 -1.8626451e-09 -9.3132257e-10\n",
      "   -9.3132257e-10 -9.3132257e-10 -9.3132257e-10 -9.3132257e-10\n",
      "   -9.3132257e-10 -4.6566129e-10 -4.6566129e-10 -4.6566129e-10\n",
      "   -4.6566129e-10 -4.6566129e-10  0.0000000e+00 -4.6566129e-10\n",
      "   -4.6566129e-10 -4.6566129e-10 -4.6566129e-10 -2.3283064e-10\n",
      "   -4.6566129e-10 -2.3283064e-10  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "    0.0000000e+00  0.0000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "t = normalise_pts(x).cpu()\n",
    "n = normalise_pts_np(x.cpu().numpy())\n",
    "\n",
    "print(t.numpy() - n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_pts(batch):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of pT-rescaled jets, each constituent pT is rescaled by 600, same shape as input\n",
    "    '''\n",
    "    batch_rscl = batch.clone()\n",
    "    batch_rscl[:,0,:] = torch.nan_to_num(batch_rscl[:,0,:]/600, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return batch_rscl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_pts_np( batch ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of pT-rescaled jets, each constituent pT is rescaled by 600, same shape as input\n",
    "    '''\n",
    "    batch_rscl = batch.copy()\n",
    "    batch_rscl[:,0,:] = np.nan_to_num(batch_rscl[:,0,:]/600, posinf = 0.0, neginf = 0.0 )\n",
    "    return batch_rscl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.2316e-02,  4.8924e-02,  3.9041e-02,  2.1909e-02,  2.1318e-02,\n",
      "           2.0094e-02,  1.0358e-02,  1.0031e-02,  8.9396e-03,  8.6376e-03,\n",
      "           8.4717e-03,  6.4226e-03,  5.9001e-03,  5.8193e-03,  5.0375e-03,\n",
      "           4.7770e-03,  4.4699e-03,  4.0331e-03,  3.4782e-03,  3.3408e-03,\n",
      "           2.5714e-03,  2.3699e-03,  2.3166e-03,  2.1685e-03,  1.8395e-03,\n",
      "           1.6398e-03,  1.5695e-03,  1.4866e-03,  1.4825e-03,  1.4456e-03,\n",
      "           1.2463e-03,  1.2226e-03,  1.1302e-03,  5.5457e-04,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [-7.9058e-02,  6.1648e-04,  6.2118e-03,  5.7302e-03,  1.8753e-02,\n",
      "          -3.3219e-04, -9.8502e-02,  1.3584e-01, -2.4150e-02, -4.8453e-02,\n",
      "           3.8021e-03, -2.3874e-02,  4.9717e-01, -4.8027e-02, -6.9739e-02,\n",
      "           1.0976e-01, -2.0094e-02,  2.8608e-02,  2.0717e-01,  1.4578e-01,\n",
      "          -1.1434e-01, -5.4460e-02,  3.9199e-02, -1.8358e-01, -5.3437e-02,\n",
      "           4.3283e-01, -1.6404e-01, -5.3426e-02,  4.2553e-02, -4.8377e-02,\n",
      "           3.5521e-01, -2.0668e-01, -1.5383e-01,  2.6020e-01,  1.8033e+00,\n",
      "           1.8033e+00,  1.8033e+00,  1.8033e+00,  1.8033e+00,  1.8033e+00,\n",
      "           1.8033e+00,  1.8033e+00,  1.8033e+00,  1.8033e+00,  1.8033e+00,\n",
      "           1.8033e+00,  1.8033e+00,  1.8033e+00,  1.8033e+00,  1.8033e+00],\n",
      "         [ 7.3412e-02,  1.0642e-01,  1.3403e-01,  1.1121e-01,  1.4011e-01,\n",
      "          -9.4133e-02,  6.2503e-02, -1.0709e-01,  6.2613e-02,  1.3622e-01,\n",
      "           3.4240e-01, -2.5538e-02,  1.6422e-01,  2.5785e-01, -5.4584e+00,\n",
      "           3.3213e-02,  3.6272e-02,  7.7335e-02, -8.4788e-02, -1.0152e-01,\n",
      "           1.5065e-01, -3.4605e-02, -4.4919e-01,  1.4322e-01, -4.9790e-02,\n",
      "           1.2726e-01,  2.1974e-01,  8.8460e-02,  5.1079e-01,  1.3131e-01,\n",
      "           5.0986e-01,  5.4430e-01,  3.3779e-01,  6.7139e-01, -5.5439e+00,\n",
      "          -5.5439e+00, -5.5439e+00, -5.5439e+00, -5.5439e+00, -5.5439e+00,\n",
      "          -5.5439e+00, -5.5439e+00, -5.5439e+00, -5.5439e+00, -5.5439e+00,\n",
      "          -5.5439e+00, -5.5439e+00, -5.5439e+00, -5.5439e+00, -5.5439e+00]]])\n",
      "[[[3.7252903e-09 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   1.8626451e-09 9.3132257e-10 9.3132257e-10 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3283064e-10 2.3283064e-10\n",
      "   2.3283064e-10 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1641532e-10\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1641532e-10 0.0000000e+00\n",
      "   1.1641532e-10 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "   0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "t = rescale_pts(x).cpu()\n",
    "n = rescale_pts_np(x.cpu().numpy())\n",
    "\n",
    "\n",
    "print(t)\n",
    "print(t.numpy() - n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_jets( batch, nc ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of cropped jets, each jet is cropped to nc constituents, shape (batchsize, 3, nc)\n",
    "    '''\n",
    "    batch_crop = batch.clone()\n",
    "    return batch_crop[:,:,0:nc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_jets_np( batch, nc ):\n",
    "    '''\n",
    "    Input: batch of jets, shape (batchsize, 3, n_constit)\n",
    "    dim 1 ordering: (pT, eta, phi)\n",
    "    Output: batch of cropped jets, each jet is cropped to nc constituents, shape (batchsize, 3, nc)\n",
    "    '''\n",
    "    batch_crop = batch.copy()\n",
    "    return batch_crop[:,:,0:nc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "t = crop_jets(x,3).cpu()\n",
    "n = crop_jets_np(x.cpu().numpy(),3)\n",
    "\n",
    "print(t.numpy() - n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
